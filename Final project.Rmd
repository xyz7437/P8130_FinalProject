---
title: "BM1 Final Project"
author: "Yijia Jiang, Yifei Xu, Xinyi Zhou, Hengxuan Ma, Chao Gao"
date: "11/16/2021"
output: pdf_document
---


# Purpose
We will be analyzing data from the "County Demographic Information" (CDI) data set, which contains characteristics of 440 counties in the United States collected from 1990-1992. The primary objective of this investigation is to develop insight relevant to predicting the crime rate in counties.


# Import the package we need
```{r setup, include=FALSE}
library(tidyverse)
library(usmap)
library(ggplot2)
library(corrplot)
library(EnvStats)
library(caret)
library(car)
library(MASS) # boxcox
library(performance) # vif
library(GGally)
library(modelr)
library(olsrr)
```



# Data preprocessing
## Transfer population variables to per capita variables
```{r}
rm(list = ls())
cdi = read.csv("./data/cdi.csv") %>%
  mutate(crime_rate = crimes/pop, 
         pcarea = area/pop,
         pcdocs = docs/pop,
         pcbeds = beds/pop,
         region = relevel(factor(region),ref = 3))
cdi_pc = cdi %>% 
  dplyr::select(crime_rate, everything(), -id, -cty, -state, -area, -docs, -beds, -crimes, -totalinc)
summary(cdi_pc)
```


# Exploratory Data Analysis
## Rank of the crime rate by state
```{r}
cdi_state <- cdi %>%
  group_by(state) %>%
  summarize(crime_rate = mean(crime_rate))
#cdi_state_rank <- cdi_state[order(-rank(cdi_state$crime_rate)),]

ggplot(cdi_state,aes(x=reorder(state,crime_rate),y=crime_rate,fill=crime_rate)) + 
  geom_bar(stat ='identity')+
  coord_flip() + 
  theme_grey() + 
  labs(title = 'Ranking of States by Crime Rate',
       y='Crime rate',x='States') +
  geom_hline(yintercept = mean(cdi$crime_rate),color = "#C9592E")+
  theme(plot.title = element_text(hjust = 0.5,size = 14, face = "bold"),
        axis.text=element_text(size=6.5))
```


## US crime rate map by state
```{r}
p<-plot_usmap(data = cdi_state, values = "crime_rate", color = "#C9592E", size = 0.5,
              labels = TRUE, label_color = "grey10") + 
   scale_fill_continuous(low = "white", high = "#C9592E", na.value = "grey90",
                         name = "Crime rate", label = scales::comma) + 
   theme(legend.position = "right") + 
   theme(panel.background = element_rect(colour = "black")) + 
   labs(title = "US Crime Rate Map") +
   theme(plot.title = element_text(hjust = 0.5,size = 14, face = "bold"))
p$layers[[2]]$aes_params$size <- 2.8
print(p)
```



## Boxplot for each variable
```{r}
par(mfrow=c(3,5))
boxplot(cdi_pc$crime_rate,  main = "crime_rate")
boxplot(cdi_pc$pop, main = "pop")
boxplot(cdi_pc$pop18, main = "pop18")
boxplot(cdi_pc$pop65, main = "pop65")
boxplot(cdi_pc$pcincome, main = "pcincome")
boxplot(cdi_pc$unemp,main = "unemp")
boxplot(cdi_pc$hsgrad, main = "hsgrad")
boxplot(cdi_pc$bagrad, main = "bagrad")
boxplot(cdi_pc$poverty, main = "poverty")
boxplot(cdi_pc$pcarea, main = "pcarea")
boxplot(cdi_pc$pcdocs, main = "pcdocs")
boxplot(cdi_pc$pcbeds, main = "pcbeds")


boxplot(crime_rate ~ region, data = cdi_pc, main = "region")
```


## Scatterplot Matrix
```{r}
pairs(~crime_rate +.,data=cdi_pc, panel = panel.smooth, upper.panel = NULL, main = "Scatterplot Matrix")
```


## Correlation plot/ Heatmap
```{r}
cdi_pc %>%
  dplyr::select(-region) %>%
  ggcorr(label = TRUE, hjust = 0.9, layout.exp = 2, label_size = 3, label_round = 2)
```


# Modelling
## Fit regression using all predictors
```{r}
mult_fit = lm(crime_rate ~ ., data = cdi_pc)
summary(mult_fit)
```


## Backwards Elimination
```{r}
mult_fit_back <- step(mult_fit, direction='backward')
mult_fit_back
```
crime_rate ~ pop + pop18 + poverty + pcincome + region + pcarea + pcbeds




# Model Diagnostics
## Create Residuals vs Fitted plot & Normal Q-Q plot & Scale-Location plot & Residuals vs Leverage plot to detect the normality of residuals and outliers
```{r}
par(mfrow=c(2,3))
plot(mult_fit_back)
plot(mult_fit_back, which = 4)
bc = boxcox(mult_fit_back)
```




## Diagnose the model without outliers
```{r}
# remove influential points
cdi_pc_out = cdi_pc[-c(1,6,412),]

# fit model with and without influential points
mult_fit_back_without = lm(crime_rate ~ pop + pop18 + poverty + pcincome + region + pcarea + pcbeds, data = cdi_pc_out)

summary(mult_fit_back)
summary(mult_fit_back_without)

# diagnose the model without outliers
par(mfrow=c(2,3))
plot(mult_fit_back_without)
plot(mult_fit_back_without, which = 4)
bc_without = boxcox(mult_fit_back_without)
```



## Box-cox transformation
```{r}
(lambda = bc_without$x[which.max(bc_without$y)])
lambda

mult_fit_back_without_trans = lm(crime_rate^0.5 ~ pop + pop18 + poverty + pcincome + 
                                 region + pcarea + pcbeds, data = cdi_pc_out)

summary(mult_fit_back_without_trans)

# Diagnose the model by square root transformation
par(mfrow = c(2,3))
plot(mult_fit_back_without_trans)
plot(mult_fit_back_without_trans, which = 4)
bc_without_trans = boxcox(mult_fit_back_without_trans)
```




## Compare the Adjusted R^2
```{r}
rbind(mult_fit_back %>% broom::glance() %>% mutate(model_type = "mult_fit_back"),
      mult_fit_back_without %>% broom::glance() %>% mutate(model_type = "mult_fit_back_without"),
      mult_fit_back_without_trans %>% broom::glance()%>% mutate(model_type = "mult_fit_back_without_trans")) %>%
        dplyr::select(model_type, everything())
```




## Assessing Multicollinearity
```{r}
# Calculate the variance inflation factor (VIF)
check_collinearity(mult_fit_back_without)

# Remove the variable with high VIF 
mult_fit_back_without_vif = lm(crime_rate ~ pop + pop18 + pcincome + region + pcarea + pcbeds, data = cdi_pc_out)
summary(mult_fit_back_without_vif)

# Diagnose the model removing poverty term
par(mfrow = c(2,3))
plot(mult_fit_back_without_vif)
plot(mult_fit_back_without_vif, which = 4)
bc_without_trans = boxcox(mult_fit_back_without_vif)
```


## Add the interaction terms
```{r}
mult_fit_back_without_int = lm(crime_rate ~ pop + pop18 + pcincome + region + pcarea + pcbeds + poverty + pcincome*poverty, data = cdi_pc_out)


summary(mult_fit_back_without_int)

anova(mult_fit_back_without,mult_fit_back_without_int)

# Diagnose the model with interaction term
par(mfrow = c(2,3))
plot(mult_fit_back_without_int)
plot(mult_fit_back_without_int, which = 4)
bc_without_trans = boxcox(mult_fit_back_without_int)
```

## Compare the Adjusted R^2 again
```{r}
rbind(mult_fit_back %>% broom::glance() %>% mutate(model_type = "mult_fit_back"),
      mult_fit_back_without %>% broom::glance() %>% mutate(model_type = "mult_fit_back_without"),
      mult_fit_back_without_trans %>% broom::glance()%>% mutate(model_type = "mult_fit_back_without_trans"),
      mult_fit_back_without_vif %>% broom::glance() %>% mutate(model_type = "mult_fit_back_without_vif"), 
      mult_fit_back_without_int %>% broom::glance() %>% mutate(model_type = "mult_fit_back_without_int")) %>%
      dplyr::select(model_type, everything())
```


## Comparison between Adjusted R squared, Cp, AIC, BIC
```{r}
model2=mult_fit_back_without
cat("Performance metrics for Model 2:\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model2)), "\nMallow's CP: ",Cp(model2,S2=(summary(model2)$sigma)^2),"\nAIC: ", AIC(model2,k=2),"\nBIC: ",AIC(model2,k=log(n)), "\n","\n")


model3=mult_fit_back_without_trans
cat("Performance metrics for Model 3:\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model3)), "\nMallow's CP: ",Cp(model3,S2=(summary(model3)$sigma)^2),"\nAIC: ", AIC(model3,k=2),"\nBIC: ",AIC(model3,k=log(n)) , "\n","\n")

model4=mult_fit_back_without_vif
cat("Performance metrics for Model 4:\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model4)), "\nMallow's CP: ",Cp(model4,S2=(summary(model4)$sigma)^2),"\nAIC: ", AIC(model4,k=2),"\nBIC: ",AIC(model4,k=log(n)) , "\n","\n")

model5=mult_fit_back_without_int
cat("Performance metrics for Model 5:\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model5)), "\nMallow's CP: ",Cp(model5,S2=(summary(model5)$sigma)^2),"\nAIC: ", AIC(model5,k=2),"\nBIC: ",AIC(model5,k=log(n)) , "\n","\n")
```


# Model Validation
## Compute RMSE and adjusted R^2 by cross-validation
```{r warning=FALSE}
set.seed(1234)
cv_df = 
  crossv_kfold(cdi_pc_out, k = 10) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>%
  mutate(
    mult_fit_back_without = map(train, ~lm(crime_rate ~ pop + pop18 + poverty + 
                                pcincome + region + pcarea + pcbeds, data = .x)),
    mult_fit_back_without_trans = map(train, ~lm(sqrt(crime_rate) ~ pop + pop18 + poverty + 
                                      pcincome + region + pcarea + pcbeds, data = .x)),
    mult_fit_back_without_vif = map(train, ~lm(crime_rate ~ pop + pop18 + 
                                    pcincome + region + pcarea + pcbeds, data = .x)),
    mult_fit_back_without_int = map(train, ~lm(crime_rate ~ pop + pop18 + pcincome + region + pcarea + pcbeds + poverty + pcincome*poverty, data = .x))) %>% 
  mutate(
    rmse_model2 = map2_dbl(mult_fit_back_without, test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(mult_fit_back_without_trans, test, ~rmse(model = .x, data = .y)),
    rmse_model4 = map2_dbl(mult_fit_back_without_vif, test, ~rmse(model = .x, data = .y)),
    rmse_model5 = map2_dbl(mult_fit_back_without_int, test, ~rmse(model = .x, data = .y))) %>%
  mutate(
    res_model2 = map(mult_fit_back_without, broom::glance %>% as.data.frame),
    res_model3 = map(mult_fit_back_without_trans, broom::glance %>% as.data.frame),
    res_model4 = map(mult_fit_back_without_vif, broom::glance %>% as.data.frame),
    res_model5 = map(mult_fit_back_without_int, broom::glance %>% as.data.frame))%>%
  unnest(res_model2, res_model3, res_model4, res_model5) %>%
  dplyr::select(rmse_model2,rmse_model3,rmse_model4,rmse_model5,
                value.adj.r.squared,value.adj.r.squared1,value.adj.r.squared2,value.adj.r.squared3,
                value.AIC ,value.AIC1, value.AIC2, value.AIC3) %>%
  rename(adjR_model2 = value.adj.r.squared,
         adjR_model3 = value.adj.r.squared1,
         adjR_model4 = value.adj.r.squared2,
         adjR_model5 = value.adj.r.squared3,
         aic_model2 = value.AIC,
         aic_model3 = value.AIC1,
         aic_model4 = value.AIC2,
         aic_model5 = value.AIC3)


cv_df %>%
  summarise_each(funs(mean( .,na.rm = TRUE))) %>%
  t()
```



## Plot the violin plot
```{r warning=FALSE}
unnest_cd_df = cv_df %>%
  pivot_longer(rmse_model2:aic_model5, 
               names_pattern = "(.*)(......)$", 
               names_to = c("limit", "model")) %>% 
  mutate(limit=ifelse(limit=="", "value", limit)) %>%
  pivot_wider(id_cols = model, 
              names_from = limit, 
              values_from = value, 
              names_repair = "check_unique") %>% 
  unnest(c(rmse_, adjR_, aic_)) %>%
  rename(rmse = rmse_,
         adjR = adjR_,
         aic = aic_)

unnest_cd_df %>% ggplot(aes(x = model, y = rmse)) + geom_violin() 
unnest_cd_df %>% ggplot(aes(x = model, y = adjR)) + geom_violin() 
unnest_cd_df %>% ggplot(aes(x = model, y = aic)) + geom_violin() 
```
```{r}
set.seed(123)
# Use 5-fold validation and create the training sets
train = trainControl(method = "cv", number = 10)

# Fit the 4-variables model that we discussed in previous lectures
model1 = train(crime_rate ~ .,
               data = cdi_pc_out,
               trControl = train,
               method = 'rpart',
               na.action = na.pass)
model2 = train(crime_rate ~ pop + pop18 + poverty + pcincome + region + pcarea + pcbeds,
               data = cdi_pc_out,
               trControl = train,
               method = 'rpart',
               na.action = na.pass)
model3 = train(sqrt(crime_rate) ~ pop + pop18 + poverty + pcincome + region + pcarea + pcbeds,
               data = cdi_pc_out,
               trControl = train,
               method = 'rpart',
               na.action = na.pass)
model4 = train(crime_rate ~ pop + pop18 + pcincome + region + pcarea + pcbeds,
               data = cdi_pc_out,
               trControl = train,
               method = 'rpart',
               na.action = na.pass)
model5 = train(crime_rate ~ pop + pop18 + pcincome + region + pcarea + pcbeds + poverty*pcincome,
              data = cdi_pc_out,
              trControl = train,
              method = 'rpart',
              na.action = na.pass)

```


```{r}
testRows=sample(nrow(cdi_pc_out),0.1*nrow(cdi_pc_out))
testData=cdi_pc_out[testRows, ]
trainData=cdi_pc_out[-testRows, ]
n=nrow(trainData)
library(boot)
library(CombMSC)
model1=lm(crime_rate ~ ., data = trainData)

model2=lm(crime_rate ~ pop + pop18 + poverty + pcincome + region + pcarea + pcbeds, data = trainData)
cat("10-fold cross validation score for Model 2: ",cv.glm(trainData,model2,K=10)$delta[1], "\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model2)), "\nMallow's CP: ",Cp(model2,S2=(summary(model2)$sigma)^2),"\nAIC: ", AIC(model2,k=2),"\nBIC: ",AIC(model2,k=log(n)), "\n")


model3=lm(sqrt(crime_rate) ~ pop + pop18 + poverty + pcincome + region + pcarea + pcbeds, data = trainData)
cat("10-fold cross validation score for Model 3: ",cv.glm(trainData,model3,K=10)$delta[1], "\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model3)), "\nMallow's CP: ",Cp(model3,S2=(summary(model3)$sigma)^2),"\nAIC: ", AIC(model3,k=2),"\nBIC: ",AIC(model3,k=log(n)) , "\n")

model4=lm(crime_rate ~ pop + pop18 + pcincome + region + pcarea + pcbeds, data = trainData)
cat("10-fold cross validation score for Model 4: ",cv.glm(trainData,model4,K=10)$delta[1], "\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model4)), "\nMallow's CP: ",Cp(model4,S2=(summary(model4)$sigma)^2),"\nAIC: ", AIC(model4,k=2),"\nBIC: ",AIC(model4,k=log(n)) , "\n")

model5=lm(crime_rate ~ pop + pop18 + pcincome + region + pcarea + pcbeds + poverty*pcincome, data = trainData)
cat("10-fold cross validation score for Model 5: ",cv.glm(trainData,model5,K=10)$delta[1], "\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model5)), "\nMallow's CP: ",Cp(model5,S2=(summary(model5)$sigma)^2),"\nAIC: ", AIC(model5,k=2),"\nBIC: ",AIC(model5,k=log(n)) , "\n")



model2=lm(crime_rate ~ pop + pop18 + poverty + pcincome + region + pcarea + pcbeds, data = trainData)
cat("10-fold cross validation score for Model 2: ",cv.glm(trainData,model2,K=10)$delta[1], "\n")
cat("Mallow's CP: ",ols_mallows_cp(model2,model1),"\nAIC: ", AIC(model2,k=2),"\nBIC: ",AIC(model2,k=log(n)), "\n")


model3=lm(sqrt(crime_rate) ~ pop + pop18 + poverty + pcincome + region + pcarea + pcbeds, data = trainData)
cat("10-fold cross validation score for Model 3: ",cv.glm(trainData,model3,K=10)$delta[1], "\n")
cat("Mallow's CP: ",ols_mallows_cp(model3,model1),"\nAIC: ", AIC(model3,k=2),"\nBIC: ",AIC(model3,k=log(n)) , "\n")

model4=lm(crime_rate ~ pop + pop18 + pcincome + region + pcarea + pcbeds, data = trainData)
cat("10-fold cross validation score for Model 4: ",cv.glm(trainData,model4,K=10)$delta[1], "\n")
cat("Mallow's CP: ",ols_mallows_cp(model4,model1),"\nAIC: ", AIC(model4,k=2),"\nBIC: ",AIC(model4,k=log(n)) , "\n")

model5=lm(crime_rate ~ pop + pop18 + pcincome + region + pcarea + pcbeds + poverty*pcincome, data = trainData)
cat("10-fold cross validation score for Model 5: ",cv.glm(trainData,model5,K=10)$delta[1], "\n")
cat("Mallow's CP: ",ols_mallows_cp(model5,model1),"\nAIC: ", AIC(model5,k=2),"\nBIC: ",AIC(model5,k=log(n)) , "\n")




```

## Comparison between Adjusted R squared, Cp, AIC, BIC
```{r}
model2=mult_fit_back_without
cat("Performance metrics for Model 2:\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model2)), "\nMallow's CP: ",Cp(model2,S2=(summary(model2)$sigma)^2),"\nAIC: ", AIC(model2,k=2),"\nBIC: ",AIC(model2,k=log(n)), "\n","\n")


model3=mult_fit_back_without_trans
cat("Performance metrics for Model 3:\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model3)), "\nMallow's CP: ",Cp(model3,S2=(summary(model3)$sigma)^2),"\nAIC: ", AIC(model3,k=2),"\nBIC: ",AIC(model3,k=log(n)) , "\n","\n")

model4=mult_fit_back_without_vif
cat("Performance metrics for Model 4:\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model4)), "\nMallow's CP: ",Cp(model4,S2=(summary(model4)$sigma)^2),"\nAIC: ", AIC(model4,k=2),"\nBIC: ",AIC(model4,k=log(n)) , "\n","\n")

model5=mult_fit_back_without_int
cat("Performance metrics for Model 5:\n")
cat("Adujsted R squared: ", -(Adj.Rsq(model5)), "\nMallow's CP: ",Cp(model5,S2=(summary(model5)$sigma)^2),"\nAIC: ", AIC(model5,k=2),"\nBIC: ",AIC(model5,k=log(n)) , "\n","\n")
```


# Thanks for reading!
